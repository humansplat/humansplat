opt_type: "tiny_uvit"

optimizer:
  name: "adamw"
  lr: 0.0004
  betas:
    - 0.9
    - 0.95
  weight_decay: 0.05

lr_scheduler:
  name: "one_cycle"
  max_lr: ${optimizer.lr}
  pct_start: 0.01

train:
  batch_size_per_gpu: 8
  epochs: 30
  log_freq: 1
  early_eval_freq: 100
  eval_freq: 1000
  save_freq: 2000
  ema_kwargs:
    decay: 0.9999
    use_ema_warmup: true
    inv_gamma: 1.
    power: 0.75

val:
  batch_size_per_gpu: 8
